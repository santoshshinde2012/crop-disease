# ðŸš€ Getting Started

[â† Back to Home](Home.md)

This guide walks you through setting up and running the Crop Disease Classification project from scratch.

---

## Prerequisites

| Requirement | Minimum | Recommended |
|-------------|---------|-------------|
| Python | 3.10+ | 3.11 |
| RAM | 8 GB | 16 GB |
| Disk Space | 2 GB (code + dataset) | 5 GB (with models) |
| GPU | Not required | NVIDIA CUDA GPU (10x faster training) |
| OS | macOS, Linux, Windows | Any |

---

## Step 1: Clone / Download the Project

If you received this as a ZIP file, extract it. Otherwise:

```bash
cd /path/to/your/workspace
# The project folder is: crop-disease/
```

---

## Step 2: Download the Dataset

1. Go to [PlantVillage Dataset on Kaggle](https://www.kaggle.com/datasets/abdallahalidev/plantvillage-dataset)
2. Download and extract the dataset
3. Place it **alongside** the project folder:

```
your-workspace/
â”œâ”€â”€ PlantVillage Dataset/
â”‚   â””â”€â”€ PlantVillage/              â† This folder has the class subfolders
â”‚       â”œâ”€â”€ Tomato_Bacterial_spot/
â”‚       â”œâ”€â”€ Tomato_Early_blight/
â”‚       â”œâ”€â”€ Potato___Early_blight/
â”‚       â”œâ”€â”€ Pepper__bell___healthy/
â”‚       â””â”€â”€ ... (other class folders)
â””â”€â”€ crop-disease/         â† The project
```

> **Note:** The notebook auto-detects the dataset path. If your dataset is in a different location, update `DATASET_ROOT` in the first few cells of the notebook.

---

## Step 3: Create a Virtual Environment

```bash
cd crop-disease

# Create virtual environment
python -m venv .venv

# Activate it
source .venv/bin/activate          # macOS / Linux
# .venv\Scripts\activate           # Windows (Command Prompt)
# .venv\Scripts\Activate.ps1      # Windows (PowerShell)
```

**Why a virtual environment?** It keeps project dependencies isolated from your system Python, preventing version conflicts with other projects.

---

## Step 4: Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

This installs all required packages:

| Package | Purpose |
|---------|---------|
| `torch`, `torchvision` | Deep learning framework (model training & inference) |
| `torchmetrics` | Efficient metric computation (accuracy, F1) |
| `numpy`, `pandas` | Numerical computing & data manipulation |
| `matplotlib`, `seaborn` | Static plots and charts |
| `Pillow` | Image loading and processing |
| `scikit-learn` | Stratified splitting, classification report |
| `tqdm` | Progress bars during training |
| `streamlit`, `plotly` | Interactive web app and charts |
| `jupyter`, `ipykernel` | Jupyter notebook support |

### Platform-Specific Notes

**macOS (Apple Silicon M1/M2/M3):**
- PyTorch uses MPS (Metal Performance Shaders) for GPU acceleration
- AMP (mixed precision) is automatically disabled on MPS
- Training is ~3-5x faster than CPU

**Linux/Windows with NVIDIA GPU:**
- Ensure CUDA toolkit is installed
- Install PyTorch with CUDA: `pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118`
- Full AMP support for fastest training

**CPU Only:**
- Everything works, just slower (~3-4 hours for full training)
- Reduce `batch_size` to 16 if RAM is limited

---

## Step 5: Run the Jupyter Notebook

```bash
# From the project root
jupyter notebook notebooks/crop_disease_classification.ipynb
```

Or if you prefer JupyterLab:
```bash
jupyter lab notebooks/crop_disease_classification.ipynb
```

Or in **VS Code**:
1. Open the project folder in VS Code
2. Open `notebooks/crop_disease_classification.ipynb`
3. Select the `.venv` Python kernel
4. Run cells sequentially with `Shift+Enter`

### Notebook Execution Order

The notebook has **8 sections** that must be run **in order**:

| Section | What It Does | Approx. Time |
|---------|-------------|--------------|
| Â§0 â€” Setup | Imports, seed, device detection | < 1 min |
| Â§1 â€” Data Exploration | Load dataset, visualize, analyze stats | 2â€“5 min |
| Â§2 â€” Data Pipeline | Split data, show augmentations, create loaders | 1â€“2 min |
| Â§3 â€” Model Training | Train 3 models through 3 stages each | 1â€“3 hours (GPU) / 3â€“6 hours (CPU) |
| Â§4 â€” Evaluation | Confusion matrices, predictions, error analysis | 5â€“10 min |
| Â§5 â€” Model Comparison | Profile models, comparison table and charts | 5â€“10 min |
| Â§6 â€” Business Recommendation | Markdown analysis (no code execution) | â€” |
| Â§7 â€” Export | Save checkpoints, class mapping, figures | < 1 min |

> **Tip:** If training is too slow, you can train only one model (e.g., EfficientNet-B0) by modifying the `model_names` list in Â§3 to `['efficientnet_b0']`.

---

## Step 6: Run the Streamlit App (Optional)

After training (so that model checkpoints exist in `models/`):

```bash
cd crop-disease
streamlit run app/streamlit_app.py
```

This opens a web browser with the disease detection app:
1. Upload a leaf photo
2. Get disease prediction with confidence score
3. See treatment recommendations

> **Note:** If no trained checkpoint exists, the app loads an untrained model for demo purposes and displays a warning.

---

## Step 7: Run the REST API (Optional)

After training (so that model checkpoints exist in `models/`):

```bash
cd crop-disease

# Development (auto-reload)
uvicorn api.app:app --reload --host 0.0.0.0 --port 8000

# Or with Docker
docker-compose up --build
```

- **Swagger UI docs:** http://localhost:8000/docs
- **Health check:** http://localhost:8000/health
- **Test prediction:**

```bash
curl -X POST "http://localhost:8000/predict" \
  -F "file=@leaf_photo.jpg" | python -m json.tool
```

> **Architecture:** The API uses SOLID principles â€” see [Deployment Guide](Deployment-Guide.md) for full details.

---

## Step 8: Verify Everything Worked

After running the full notebook, two runtime directories are created with the following outputs:

```
crop-disease/
â”œâ”€â”€ models/                             â† created at runtime
â”‚   â”œâ”€â”€ resnet50_best.pth               â† ~98 MB
â”‚   â”œâ”€â”€ efficientnet_b0_best.pth        â† ~20 MB
â”‚   â”œâ”€â”€ mobilenetv3_best.pth            â† ~10 MB
â”‚   â”œâ”€â”€ class_mapping.json              â† Class index â†” name mapping
â”‚   â””â”€â”€ training_config.json            â† Full config + results
â””â”€â”€ outputs/                            â† created at runtime
    â”œâ”€â”€ sample_images_grid.png
    â”œâ”€â”€ class_distribution.png
    â”œâ”€â”€ training_curves.png
    â”œâ”€â”€ confusion_matrix_resnet50.png
    â”œâ”€â”€ confusion_matrix_efficientnet_b0.png
    â”œâ”€â”€ confusion_matrix_mobilenetv3.png
    â”œâ”€â”€ correct_predictions.png
    â”œâ”€â”€ incorrect_predictions.png
    â””â”€â”€ model_comparison.png
```

---

## Folder Structure Explained

```
crop-disease/
â”‚
â”œâ”€â”€ src/                              # Source code (modular, reusable)
â”‚   â”œâ”€â”€ config.py                     # ALL hyperparameters live here
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py                # Custom PyTorch Dataset class
â”‚   â”‚   â”œâ”€â”€ transforms.py             # Image augmentation pipelines
â”‚   â”‚   â”œâ”€â”€ splitter.py               # Train/val/test stratified splitting
â”‚   â”‚   â””â”€â”€ loader.py                 # DataLoader creation
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ factory.py                # Model creation & param utilities
â”‚   â”‚   â””â”€â”€ freeze.py                 # Layer freezing / unfreezing
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ trainer.py                # Training loop & checkpointing
â”‚   â”‚   â”œâ”€â”€ scheduler.py              # LR scheduler factory
â”‚   â”‚   â””â”€â”€ early_stopping.py         # EarlyStopping callback
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ metrics.py                # Predictions, classification report
â”‚   â”‚   â”œâ”€â”€ confusion.py              # Confusion matrix heatmap
â”‚   â”‚   â”œâ”€â”€ predictions.py            # Correct/incorrect prediction grids
â”‚   â”‚   â””â”€â”€ profiler.py               # Model latency & size measurement
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ seed.py                   # Reproducibility (random seed management)
â”‚       â”œâ”€â”€ text_helpers.py           # Class-name shortening & crop extraction
â”‚       â”œâ”€â”€ plot_data.py              # Data exploration plots
â”‚       â”œâ”€â”€ plot_training.py          # Training & comparison plots
â”‚       â””â”€â”€ export.py                 # ONNX model export
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ crop_disease_classification.ipynb   # Main notebook â€” runs everything
â”‚
â”œâ”€â”€ app/                              # Streamlit web application (5 modules)
â”‚   â”œâ”€â”€ streamlit_app.py              # Entry point
â”‚   â”œâ”€â”€ config.py                     # App constants & thresholds
â”‚   â”œâ”€â”€ disease_info.py               # Disease database & helpers
â”‚   â”œâ”€â”€ model_service.py              # Checkpoint loading & prediction
â”‚   â””â”€â”€ ui_components.py              # Sidebar, results, chart widgets
â”‚
â”œâ”€â”€ api/                              # FastAPI REST API (SOLID architecture)
â”‚   â”œâ”€â”€ app.py                        # Application factory
â”‚   â”œâ”€â”€ schemas.py                    # Pydantic request/response models
â”‚   â”œâ”€â”€ protocols.py                  # Abstract interfaces (DIP)
â”‚   â”œâ”€â”€ dependencies.py               # FastAPI dependency injection
â”‚   â”œâ”€â”€ middleware.py                 # CORS, request logging
â”‚   â”œâ”€â”€ routes/                       # Endpoint handlers
â”‚   â”‚   â”œâ”€â”€ health.py                 # GET /health, GET /model/version
â”‚   â”‚   â””â”€â”€ predict.py                # POST /predict
â”‚   â””â”€â”€ services/                     # Business logic
â”‚       â”œâ”€â”€ inference_service.py      # PyTorch model inference
â”‚       â””â”€â”€ disease_service.py        # Disease info enrichment
â”œâ”€â”€ scripts/                          # CLI utilities
â”‚   â””â”€â”€ export_model.py              # PyTorch â†’ ONNX â†’ TFLite pipeline
â”œâ”€â”€ tests/                            # Unit tests (78 passing, 1 skipped)
â”œâ”€â”€ wiki/                             # Documentation (you're reading it!)
â”œâ”€â”€ pyproject.toml                    # Package config & tool settings
â”œâ”€â”€ requirements.txt                  # Python package list
â”œâ”€â”€ requirements-api.txt              # Lean API-only dependencies
â”œâ”€â”€ Dockerfile                        # Multi-stage API container
â”œâ”€â”€ Dockerfile.hf                     # Hugging Face Spaces container
â”œâ”€â”€ docker-compose.yml                # Local development setup
â”œâ”€â”€ render.yaml                       # Render IaC Blueprint
â”œâ”€â”€ .streamlit/config.toml            # Streamlit headless config & theme
â”œâ”€â”€ .dockerignore                     # Docker build exclusions
â”œâ”€â”€ .gitignore                        # Files excluded from version control
â”œâ”€â”€ DEPLOYMENT.md                     # End-to-end cloud deployment guide
â””â”€â”€ README.md                         # Project summary
```

> **Note:** `models/` and `outputs/` directories are created at runtime during training.

---

## Next Steps

| What | Where |
|------|-------|
| Understand the project structure | [Architecture Overview](Architecture-Overview.md) |
| Walk through every requirement | [Task Walkthrough](Task-Walkthrough.md) |
| Learn how data flows through the system | [Data Pipeline](Data-Pipeline.md) |
| Understand the training strategy | [Model Training](Model-Training.md) |
| Interpret evaluation results | [Evaluation & Metrics](Evaluation-and-Metrics.md) |
| Deploy to production (API or mobile) | [Deployment Guide](Deployment-Guide.md) |
| Deploy for free on the cloud | [Cloud Deployment](Cloud-Deployment.md) |
| Step-by-step sharing plan | [Sharing Plan](Sharing-Plan.md) |
| Fix common errors | [FAQ & Troubleshooting](FAQ-and-Troubleshooting.md) |
